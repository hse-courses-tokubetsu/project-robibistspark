{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашняя работа №2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robib\\anaconda3\\lib\\site-packages\\thinc\\compat.py:36: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  hasattr(torch, \"has_mps\")\n",
      "C:\\Users\\robib\\anaconda3\\lib\\site-packages\\thinc\\compat.py:37: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  and torch.has_mps  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from spacy import load\n",
    "from rank_bm25 import BM25Okapi\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from navec import Navec\n",
    "from numpy.linalg import norm\n",
    "from sys import getsizeof\n",
    "from nltk import sent_tokenize\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch import no_grad\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Корпус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я взял корпус новостей Collection5, создававшийся для NER. В нём собрана 1000 достаточно коротких текстов в виде .txt-файлов (а также аннотации, не нужные мне). Этот корпус позволил избежать необходимости разбираться с лишними данными и ускорить работу. Источник: https://github.com/natasha/corus#reference, а именно данные по http://www.labinform.ru/pub/named_entities/collection5.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Россия рассчитывает на конструктивное воздейст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Комиссар СЕ критикует ограничительную политику...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Пулеметы, автоматы и снайперские винтовки изъя...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 октября назначены очередные выборы Верховног...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Следственное управление при прокуратуре требуе...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Россия рассчитывает на конструктивное воздейст...\n",
       "1  Комиссар СЕ критикует ограничительную политику...\n",
       "2  Пулеметы, автоматы и снайперские винтовки изъя...\n",
       "3  4 октября назначены очередные выборы Верховног...\n",
       "4  Следственное управление при прокуратуре требуе..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'text': []}\n",
    "\n",
    "for file in listdir('collection5'):\n",
    "    if str(file).endswith('txt'):\n",
    "        with open(f'collection5/{str(file)}', encoding='utf-8') as f:\n",
    "            d['text'].append(f.read())\n",
    "\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"corpus.pickle\", \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Предобработка\n",
    "Удаляются служебные части речи, стоп-слова, небуквенные токены. PoS-тэги через Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robib\\anaconda3\\lib\\site-packages\\spacy\\util.py:877: UserWarning: [W095] Model 'ru_core_news_lg' (3.2.0) was trained with spaCy v3.2 and may not be 100% compatible with the current version (3.5.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "stops = stopwords.words('russian')\n",
    "nlp = load(\"ru_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str, pos_needed=False) -> str:\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    text_lemmas = []\n",
    "    if pos_needed is False:\n",
    "        for sent in doc.sents:\n",
    "            for i in sent: \n",
    "                if i.text.isalpha() is True \\\n",
    "                and i.text not in stopwords.words('russian') \\\n",
    "                and i.pos_ in ['ADJ', 'ADV', 'NOUN', 'PROPN', 'VERB']:\n",
    "                    text_lemmas.append(i.lemma_)\n",
    "    elif pos_needed is True:\n",
    "        for sent in doc.sents:\n",
    "            for i in sent: \n",
    "                if i.text.isalpha() is True \\\n",
    "                and i.text not in stopwords.words('russian') \\\n",
    "                and i.pos_ in ['ADJ', 'ADV', 'NOUN', 'PROPN', 'VERB']:\n",
    "                    text_lemmas.append(i.lemma_ + '_' + i.pos_)\n",
    "    \n",
    "    return text_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemmas_list</th>\n",
       "      <th>lemmas_pos_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Россия рассчитывает на конструктивное воздейст...</td>\n",
       "      <td>[россия, рассчитывать, конструктивный, воздейс...</td>\n",
       "      <td>[россия_PROPN, рассчитывать_VERB, конструктивн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Комиссар СЕ критикует ограничительную политику...</td>\n",
       "      <td>[комиссар, се, критиковать, ограничительный, п...</td>\n",
       "      <td>[комиссар_NOUN, се_PROPN, критиковать_VERB, ог...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Пулеметы, автоматы и снайперские винтовки изъя...</td>\n",
       "      <td>[пулемёт, автомат, снайперский, винтовка, изъя...</td>\n",
       "      <td>[пулемёт_NOUN, автомат_NOUN, снайперский_ADJ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 октября назначены очередные выборы Верховног...</td>\n",
       "      <td>[октябрь, назначить, очередной, выбор, верховн...</td>\n",
       "      <td>[октябрь_NOUN, назначить_VERB, очередной_ADJ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Следственное управление при прокуратуре требуе...</td>\n",
       "      <td>[следственный, управление, прокуратура, требов...</td>\n",
       "      <td>[следственный_ADJ, управление_NOUN, прокуратур...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Россия рассчитывает на конструктивное воздейст...   \n",
       "1  Комиссар СЕ критикует ограничительную политику...   \n",
       "2  Пулеметы, автоматы и снайперские винтовки изъя...   \n",
       "3  4 октября назначены очередные выборы Верховног...   \n",
       "4  Следственное управление при прокуратуре требуе...   \n",
       "\n",
       "                                         lemmas_list  \\\n",
       "0  [россия, рассчитывать, конструктивный, воздейс...   \n",
       "1  [комиссар, се, критиковать, ограничительный, п...   \n",
       "2  [пулемёт, автомат, снайперский, винтовка, изъя...   \n",
       "3  [октябрь, назначить, очередной, выбор, верховн...   \n",
       "4  [следственный, управление, прокуратура, требов...   \n",
       "\n",
       "                                     lemmas_pos_list  \n",
       "0  [россия_PROPN, рассчитывать_VERB, конструктивн...  \n",
       "1  [комиссар_NOUN, се_PROPN, критиковать_VERB, ог...  \n",
       "2  [пулемёт_NOUN, автомат_NOUN, снайперский_ADJ, ...  \n",
       "3  [октябрь_NOUN, назначить_VERB, очередной_ADJ, ...  \n",
       "4  [следственный_ADJ, управление_NOUN, прокуратур...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmas_list'] = df.text.apply(preprocess_text)\n",
    "df['lemmas_pos_list'] = df.text.apply(preprocess_text, pos_needed=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Обратный индекс BM-25Okapi через библиотеку\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rank_bm25.BM25Okapi at 0x1c9633bb910>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25 = BM25Okapi(df.lemmas_list)\n",
    "bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bm25.pickle\", \"wb\") as f:\n",
    "    pickle.dump(bm25, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Индекс текстов через word2vec\n",
    "Я загрузил модель ruwikiruscorpora_upos_cbow_300_10_2021 с сайта RusVectōrēs https://rusvectores.org/ru/models/. Вектор документа находится как среднее арифметическое векторов входящих в него слов. Слова, которых нет в модели, выкидываются из суммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_OOVs(lemmas_list, model):\n",
    "    clean = []\n",
    "    for lemma in lemmas_list:\n",
    "        try:\n",
    "            model[lemma]\n",
    "            clean.append(lemma)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = KeyedVectors.load_word2vec_format('model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemmas_list</th>\n",
       "      <th>lemmas_pos_list</th>\n",
       "      <th>lemmas_pos_list_w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Россия рассчитывает на конструктивное воздейст...</td>\n",
       "      <td>[россия, рассчитывать, конструктивный, воздейс...</td>\n",
       "      <td>[россия_PROPN, рассчитывать_VERB, конструктивн...</td>\n",
       "      <td>[россия_PROPN, рассчитывать_VERB, конструктивн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Комиссар СЕ критикует ограничительную политику...</td>\n",
       "      <td>[комиссар, се, критиковать, ограничительный, п...</td>\n",
       "      <td>[комиссар_NOUN, се_PROPN, критиковать_VERB, ог...</td>\n",
       "      <td>[комиссар_NOUN, се_PROPN, критиковать_VERB, ог...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Пулеметы, автоматы и снайперские винтовки изъя...</td>\n",
       "      <td>[пулемёт, автомат, снайперский, винтовка, изъя...</td>\n",
       "      <td>[пулемёт_NOUN, автомат_NOUN, снайперский_ADJ, ...</td>\n",
       "      <td>[пулемёт_NOUN, автомат_NOUN, снайперский_ADJ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 октября назначены очередные выборы Верховног...</td>\n",
       "      <td>[октябрь, назначить, очередной, выбор, верховн...</td>\n",
       "      <td>[октябрь_NOUN, назначить_VERB, очередной_ADJ, ...</td>\n",
       "      <td>[октябрь_NOUN, назначить_VERB, очередной_ADJ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Следственное управление при прокуратуре требуе...</td>\n",
       "      <td>[следственный, управление, прокуратура, требов...</td>\n",
       "      <td>[следственный_ADJ, управление_NOUN, прокуратур...</td>\n",
       "      <td>[следственный_ADJ, управление_NOUN, прокуратур...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Россия рассчитывает на конструктивное воздейст...   \n",
       "1  Комиссар СЕ критикует ограничительную политику...   \n",
       "2  Пулеметы, автоматы и снайперские винтовки изъя...   \n",
       "3  4 октября назначены очередные выборы Верховног...   \n",
       "4  Следственное управление при прокуратуре требуе...   \n",
       "\n",
       "                                         lemmas_list  \\\n",
       "0  [россия, рассчитывать, конструктивный, воздейс...   \n",
       "1  [комиссар, се, критиковать, ограничительный, п...   \n",
       "2  [пулемёт, автомат, снайперский, винтовка, изъя...   \n",
       "3  [октябрь, назначить, очередной, выбор, верховн...   \n",
       "4  [следственный, управление, прокуратура, требов...   \n",
       "\n",
       "                                     lemmas_pos_list  \\\n",
       "0  [россия_PROPN, рассчитывать_VERB, конструктивн...   \n",
       "1  [комиссар_NOUN, се_PROPN, критиковать_VERB, ог...   \n",
       "2  [пулемёт_NOUN, автомат_NOUN, снайперский_ADJ, ...   \n",
       "3  [октябрь_NOUN, назначить_VERB, очередной_ADJ, ...   \n",
       "4  [следственный_ADJ, управление_NOUN, прокуратур...   \n",
       "\n",
       "                                 lemmas_pos_list_w2v  \n",
       "0  [россия_PROPN, рассчитывать_VERB, конструктивн...  \n",
       "1  [комиссар_NOUN, се_PROPN, критиковать_VERB, ог...  \n",
       "2  [пулемёт_NOUN, автомат_NOUN, снайперский_ADJ, ...  \n",
       "3  [октябрь_NOUN, назначить_VERB, очередной_ADJ, ...  \n",
       "4  [следственный_ADJ, управление_NOUN, прокуратур...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmas_pos_list_w2v'] = df.lemmas_pos_list.apply(delete_OOVs, model=w2v_model)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_index = np.zeros((1000, 300)) # 1000 texts, vectors of length 300\n",
    "for n, lemmas_list in enumerate(df['lemmas_pos_list_w2v']):\n",
    "    w2v_index[n] = np.mean(w2v_model[lemmas_list], axis=0)\n",
    "w2v_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"w2v_index.pickle\", \"wb\") as f:\n",
    "    pickle.dump(w2v_index, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Индекс текстов через navec\n",
    "Я использовал модель Навек для новостных текстов с сайта https://github.com/natasha/navec. (Снова) вектор документа находится как среднее арифметическое векторов входящих в него слов, а слова, которых нет в модели, выкидываются из суммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "navec = Navec.load('navec_news_v1_1B_250K_300d_100q.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemmas_list</th>\n",
       "      <th>lemmas_pos_list</th>\n",
       "      <th>lemmas_pos_list_w2v</th>\n",
       "      <th>lemmas_list_navec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Россия рассчитывает на конструктивное воздейст...</td>\n",
       "      <td>[россия, рассчитывать, конструктивный, воздейс...</td>\n",
       "      <td>[россия_PROPN, рассчитывать_VERB, конструктивн...</td>\n",
       "      <td>[россия_PROPN, рассчитывать_VERB, конструктивн...</td>\n",
       "      <td>[россия, рассчитывать, конструктивный, воздейс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Комиссар СЕ критикует ограничительную политику...</td>\n",
       "      <td>[комиссар, се, критиковать, ограничительный, п...</td>\n",
       "      <td>[комиссар_NOUN, се_PROPN, критиковать_VERB, ог...</td>\n",
       "      <td>[комиссар_NOUN, се_PROPN, критиковать_VERB, ог...</td>\n",
       "      <td>[комиссар, се, критиковать, ограничительный, п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Пулеметы, автоматы и снайперские винтовки изъя...</td>\n",
       "      <td>[пулемёт, автомат, снайперский, винтовка, изъя...</td>\n",
       "      <td>[пулемёт_NOUN, автомат_NOUN, снайперский_ADJ, ...</td>\n",
       "      <td>[пулемёт_NOUN, автомат_NOUN, снайперский_ADJ, ...</td>\n",
       "      <td>[пулемёт, автомат, снайперский, винтовка, изъя...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 октября назначены очередные выборы Верховног...</td>\n",
       "      <td>[октябрь, назначить, очередной, выбор, верховн...</td>\n",
       "      <td>[октябрь_NOUN, назначить_VERB, очередной_ADJ, ...</td>\n",
       "      <td>[октябрь_NOUN, назначить_VERB, очередной_ADJ, ...</td>\n",
       "      <td>[октябрь, назначить, очередной, выбор, верховн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Следственное управление при прокуратуре требуе...</td>\n",
       "      <td>[следственный, управление, прокуратура, требов...</td>\n",
       "      <td>[следственный_ADJ, управление_NOUN, прокуратур...</td>\n",
       "      <td>[следственный_ADJ, управление_NOUN, прокуратур...</td>\n",
       "      <td>[следственный, управление, прокуратура, требов...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Россия рассчитывает на конструктивное воздейст...   \n",
       "1  Комиссар СЕ критикует ограничительную политику...   \n",
       "2  Пулеметы, автоматы и снайперские винтовки изъя...   \n",
       "3  4 октября назначены очередные выборы Верховног...   \n",
       "4  Следственное управление при прокуратуре требуе...   \n",
       "\n",
       "                                         lemmas_list  \\\n",
       "0  [россия, рассчитывать, конструктивный, воздейс...   \n",
       "1  [комиссар, се, критиковать, ограничительный, п...   \n",
       "2  [пулемёт, автомат, снайперский, винтовка, изъя...   \n",
       "3  [октябрь, назначить, очередной, выбор, верховн...   \n",
       "4  [следственный, управление, прокуратура, требов...   \n",
       "\n",
       "                                     lemmas_pos_list  \\\n",
       "0  [россия_PROPN, рассчитывать_VERB, конструктивн...   \n",
       "1  [комиссар_NOUN, се_PROPN, критиковать_VERB, ог...   \n",
       "2  [пулемёт_NOUN, автомат_NOUN, снайперский_ADJ, ...   \n",
       "3  [октябрь_NOUN, назначить_VERB, очередной_ADJ, ...   \n",
       "4  [следственный_ADJ, управление_NOUN, прокуратур...   \n",
       "\n",
       "                                 lemmas_pos_list_w2v  \\\n",
       "0  [россия_PROPN, рассчитывать_VERB, конструктивн...   \n",
       "1  [комиссар_NOUN, се_PROPN, критиковать_VERB, ог...   \n",
       "2  [пулемёт_NOUN, автомат_NOUN, снайперский_ADJ, ...   \n",
       "3  [октябрь_NOUN, назначить_VERB, очередной_ADJ, ...   \n",
       "4  [следственный_ADJ, управление_NOUN, прокуратур...   \n",
       "\n",
       "                                   lemmas_list_navec  \n",
       "0  [россия, рассчитывать, конструктивный, воздейс...  \n",
       "1  [комиссар, се, критиковать, ограничительный, п...  \n",
       "2  [пулемёт, автомат, снайперский, винтовка, изъя...  \n",
       "3  [октябрь, назначить, очередной, выбор, верховн...  \n",
       "4  [следственный, управление, прокуратура, требов...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmas_list_navec'] = df.lemmas_list.apply(delete_OOVs, model=navec)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navec_index = np.zeros((1000, 300)) # 1000 texts, vectors of length 300\n",
    "for n, lemmas_list in enumerate(df['lemmas_list_navec']):\n",
    "    vec = np.zeros((1, 300))\n",
    "    for word in lemmas_list:\n",
    "        vec += navec[word]\n",
    "    navec_index[n] = vec / len(lemmas_list)\n",
    "navec_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"navec_index.pickle\", \"wb\") as f:\n",
    "    pickle.dump(navec_index, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Индекс с помощью BERT\n",
    "По каждому документу проходимся по предложениям, считаем эмбеддинг для предложения (берём CLS, хотя разработчики модели рекомендуют среднее арифметическое токенов), складываем все эти эмбеддинги и делим на количество предложений в документе - так получаем эмбеддинг документа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/sbert_large_nlu_ru\")\n",
    "BERT_model = AutoModel.from_pretrained(\"sberbank-ai/sbert_large_nlu_ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sent, tokenizer, model):\n",
    "        for s in [sent]:\n",
    "            encoded_input = tokenizer(s, padding=True, truncation=True, max_length=64, return_tensors='pt')\n",
    "            with no_grad():\n",
    "                model_output = model(**encoded_input)\n",
    "        \n",
    "        return model_output[0][0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encode(df['text'][0], tokenizer, BERT_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1024)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_index = np.zeros((1000, 1024)) # 1000 texts, vectors of length 1024\n",
    "for n, text in enumerate(df['text']):\n",
    "    vec = np.zeros((1, 1024))\n",
    "    text_list = sent_tokenize(text)\n",
    "    for sent in text_list:\n",
    "        vec += encode(sent, tokenizer, BERT_model)\n",
    "    bert_index[n] = vec / len(text_list)\n",
    "bert_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bert_index.pickle\", \"wb\") as f:\n",
    "    pickle.dump(bert_index, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Поиск\n",
    "В качестве оценки сходства используется косинусная близость (кроме BM-25, где своё ранжирование). Я показываю 2 самых релевантных документа, но имеется параметр, чтобы управлять этим числом. Вектор запроса находится как среднее арифметическое векторов входящих в него слов, а слова, которых нет в модели, выкидываются из суммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_index(query: str, index_type: str, n=2):\n",
    "    \n",
    "    if index_type == 'bm25':\n",
    "        \n",
    "        clean_query = preprocess_text(query)\n",
    "        \n",
    "        ranked_docs = bm25.get_top_n(clean_query, df.text, n=n)\n",
    "    \n",
    "        return ranked_docs\n",
    "    \n",
    "    elif index_type == 'w2v':\n",
    "        \n",
    "        clean_query = delete_OOVs(preprocess_text(query, pos_needed=True), model=w2v_model)\n",
    "        \n",
    "        query_vector = np.mean(w2v_model[clean_query], axis=0)\n",
    "        \n",
    "        cos_sims = np.dot(w2v_index, query_vector) / (norm(w2v_index, axis=1) * norm(query_vector))\n",
    "        \n",
    "        d = {}\n",
    "        for i, j in enumerate(cos_sims):\n",
    "            d[i] = j\n",
    "        ranking = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return [df['text'][ranking[i][0]] for i in range(n)]\n",
    "        \n",
    "    elif index_type == 'navec':\n",
    "        \n",
    "        clean_query = delete_OOVs(preprocess_text(query), model=navec)\n",
    "        \n",
    "        vec = np.zeros((1, 300))\n",
    "        for word in clean_query:\n",
    "            vec += navec[word]\n",
    "        query_vector = vec / len(clean_query)\n",
    "        \n",
    "        cos_sims = np.dot(navec_index, query_vector.transpose()) / (norm(navec_index, axis=1) * norm(query_vector))\n",
    "        \n",
    "        d = {}\n",
    "        for i, j in enumerate(cos_sims):\n",
    "            d[i] = j[0]\n",
    "        \n",
    "        ranking = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return [df['text'][ranking[i][0]] for i in range(n)]\n",
    "    \n",
    "    elif index_type == 'bert':\n",
    "        \n",
    "        vec = np.zeros((1, 1024))\n",
    "        query_list = sent_tokenize(query)\n",
    "        for sent in text_list:\n",
    "            vec += encode(sent, tokenizer, BERT_model)\n",
    "        query_vector = vec / len(text_list)\n",
    "        \n",
    "        cos_sims = np.dot(bert_index, query_vector.transpose()) / \\\n",
    "            (norm(bert_index, axis=1) * norm(query_vector))\n",
    "        \n",
    "        d = {}\n",
    "        for i, j in enumerate(cos_sims):\n",
    "            d[i] = j[0]\n",
    "        \n",
    "        ranking = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        return [df['text'][ranking[i][0]] for i in range(n)]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print('Invalid index type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Сравнение реузльтатов\n",
    "Время обработки (среднее из %%timeit) приведено для одного запроса, определённого выше. Нужно заметить, что создание индекса для w2v дольше за счёт необходимости парсить часть речи, и для BERT долгое, так как нейросеть энкодит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Телефон, оператор'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.4 ms ± 1.52 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "search_index(query, index_type='bm25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.7 ms ± 3.31 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "search_index(query, index_type='w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.3 ms ± 2.98 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "search_index(query, index_type='navec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327 ms ± 24.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "search_index(query, index_type='bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608164 2400128 2400128 8192128\n"
     ]
    }
   ],
   "source": [
    "print(getsizeof(bm25), getsizeof(w2v_index), getsizeof(navec_index), getsizeof(bert_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Index type    | Average time, ms  | Memory, bytes |\n",
    "|:-------------:|:----------------- |:------------- |\n",
    "| BM-25         | 10.4              | 608164        |\n",
    "| Word2Vec      | 22.7              | 2400128       |\n",
    "| Navec         | 23.3              | 2400128       |\n",
    "| BERT          | 327               | 8192128       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замечание: результаты с BERT плохие и, видимо, зависят от длины запроса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Вице-мэром Новосибирска по социальным вопросам стал учитель\\n10:14 31.01.2013\\n\\nМэр Новосибирска Владимир Городецкий назначил своим заместителем по социальным вопросам бывшего замначальника городского управления образования Сергея Нелюбова; главным финансистом города стал бывший первый замглавы Бердска Владимир Штоп.',\n",
       " 'Медведев назначил полпредом в ЦФО Олега Говоруна\\n\\nДмитрий Медведев назначил главу президентского управления внутренней политики Олега Говоруна полпредом главы государства в Центральном федеральном округе, сообщила во вторник пресс-служба Кремля.\\n\\nПост полпреда президента в ЦФО стал вакантным после того, как на прошлой неделе занимавший эту должность 11 лет Георгий Полтавченко стал губернатором Петербурга.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_index(query, index_type='bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Command Line Interface\n",
    "Дольше из-за того, что при запуске команды в память загружается модель для индексирования запроса. Проблема: не парсятся запросы длиной больше одного слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time, s: 4.021940469741821\n",
      "\n",
      "['Apple уволила менеджера, отвечавшего за картографический сервис\\nApple logo\\n© AFP/ Kimihiro Hoshino\\nВ прошлом месяце Apple заявила об отставке главы по разработке iOS Скотта Форсталла, в ведение которого также входило создание картографического сервиса Apple.\\n28/11/201211:37\\nКлючевые слова: Apple\\n\\nНЬЮКАСЛ (Великобритания), 28 ноя — РИА Новости, Алина Гайнуллина. Компания Apple уволила менеджера Ричарда Уильямсона (Richard Williamson), руководившего командой по разработке ее картографического сервиса, и надеется вернуть доверие недовольных программой пользователей, сообщает агентство Bloomberg со ссылкой на информированные источники.\\n\\nМобильная операционная система iOS 6 стала первой, в которой в качестве штатного картографического приложения Apple использовала собственные карты, а не Google Maps. Новые карты Apple вызвали резкую критику пользователей за неточность отображения ландшафта и маршрутов, отсутствие маршрутов общественного транспорта и другие недочеты.\\n\\nВ прошлом месяце Apple заявила об отставке главы по разработке iOS Скотта Форсталла, в ведение которого также входило создание картографического сервиса Apple. По данным WSJ, Форсталл отказался подписать открытое письмо с извинениями, адресованное пользователям. В итоге это письмо было опубликовано за подписью гендиректора Тима Кука. С октября разработка карт Apple ведется под надзором руководителя интернет-сервисов Эдди Кью.\\n\\nКак пишет Bloomberg, после отставки Форсталла Apple уволила также менеджера Ричарда Уильямсона, который возглавлял команду, ведущую непосредственно разработку картографического сервиса. По данным источников агентства, увольнение было инициировано самим Эдди Кью, который хочет назначить в подразделении новую управленческую команду. Найден ли уже преемник Уильямсону, не уточняется.\\n\\nПомимо кадровых перестановок, Кью консультируется сейчас с экспертами в области картографических технологий, чтобы исправить ошибки и недоработки карт Apple, отмечает Bloomberg.\\n\\nПредставители Apple отказались прокомментировать Bloomberg данную информацию, отметив лишь, что компания действительно старается доработать сервис для пользователей.\\n\\nGoogle и Apple сотрудничали со времени запуска первой версии iOS и первого iPhone в 2007 году. Однако позднее Apple решила отказаться от предустановки Google Maps, а также приложения видеосервиса YouTube в новой платформе iOS 6. Подобное решение отчасти связано с ожесточенной конкуренцией между компаниями на мобильном рынке.\\n\\nВ преддверии выхода iOS 6 Google уже выпустила официальное iPhone-приложение для работы с видеопорталом YouTube. Сейчас, по данным The Wall Street Journal, Google вносит последние доработки в новое картографическое приложение для iPhone прежде чем отправить его на рассмотрение в Apple App Store.\\n\\nЕсли Apple примет новое приложение Google в свой онлайн-магазин, то оно будет напрямую конкурировать с собственными картами компании. Еще одним конкурентом станут сервисы Here от Nokia — компания недавно запустила картографическое приложение для iOS.\\n\\nApple и Google являются главными конкурентами на рынке мобильных операционных систем — программная платформа iOS лидирует в сегменте планшетных компьютеров, а Android — на рынке смартфонов.\\n\\n\\nЧитайте далее: http://ai-center.botik.ru/isida-r/demo/rsser-show-archive-file.php?url=45184#ixzz2DbP5Xb1A\\n', 'Skype уволил нескольких топ-менеджеров\\n\\nКомпания Skype Technologies S.A., управляющая сервисом интернет-телефонии Skype, уволила нескольких человек из состава своего высшего руководства. Об этом пишет Businessweek со ссылкой на источник, знакомый с ситуацией внутри компании и пожелавший остаться неизвестным.\\n\\nДолжности в Skype, по данным издания, лишились четыре вице-президента компании: Дэвид Гурл (David Gurle), Кристофер Дин (Christopher Dean), Дон Альберт (Don Albert) и Расс Шоу (Russ Shaw). Последний отвечал, в частности, за связи Skype с мобильными операторами и производителями мобильных телефонов.\\n\\nКроме того, были уволены директор по маркетингу Даг Бьюшер (Doug Bewsher) и Энн Гиллеспи (Anne Gillespie), возглавлявшая отдел кадров компании, а также руководители Qik Раму Сункара (Ramu Sunkara) и Эллисон Кампа (Allyson Campa). Сервис Qik Skype приобрел в январе 2011 года за 100 миллионов долларов.\\n\\nИсполнительный директор Skype Тони Бейтс (Tony Bates) сохранил свой пост. Предполагается, что он займет должность главы подразделения Skype, которое будет создано в составе Microsoft.\\n\\nИсточник Bloomberg предполагает, что увольнение топ-менеджеров до завершения сделки между Skype и Microsoft позволило компании сэкономить на выплатах компенсаций уволенным. Если бы Microsoft на момент их увольнения была полноправным владельцем Skype, размер выплат был бы больше.\\n\\nО покупке Skype корпорацией Microsoft было объявлено 10 мая. За Skype Microsoft заплатит 8,5 миллиардов долларов, включая долги. 17 июня сделку утвердила Федеральная комиссия по торговле США (FTC).\\n\\nMicrosoft планирует интегрировать Skype с рядом собственных сервисов, в том числе с игровой консолью Xbox 360, мобильной операционной системой Windows Phone, почтовым клиентом Outlook и ориентированной на бизнес-пользователей коммуникационной платформой Lync. ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robib\\anaconda3\\lib\\site-packages\\thinc\\compat.py:36: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  hasattr(torch, \"has_mps\")\n",
      "C:\\Users\\robib\\anaconda3\\lib\\site-packages\\thinc\\compat.py:37: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  and torch.has_mps  # type: ignore[attr-defined]\n",
      "C:\\Users\\robib\\anaconda3\\lib\\site-packages\\spacy\\util.py:877: UserWarning: [W095] Model 'ru_core_news_lg' (3.2.0) was trained with spaCy v3.2 and may not be 100% compatible with the current version (3.5.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "!python main.py телефон w2v 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
